{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQEfn0Br2Bw9",
        "outputId": "f9c4543d-193a-4774-dc0d-b08c55f3e7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaRxyGGW2dKW",
        "outputId": "c8401bda-3e46-4e36-a11b-36e358fa89bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ReportCC++/vulberta\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/ReportCC++/vulberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpkKOfYv2i0V",
        "outputId": "67d2403b-a60b-477a-caa1-76fd32fb5fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa\n"
          ]
        }
      ],
      "source": [
        "cd VulBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C1qQ5idWevHi",
        "outputId": "70d871fe-5580-4c60-d97c-4ba30a000188"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCZhGZmG2qzg",
        "outputId": "c88c7607-fbc5-437d-8a43-fc2351eb88be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/7.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/7.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.13.3\n"
          ]
        }
      ],
      "source": [
        "! pip install tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wDHNWyw3Jcl",
        "outputId": "5961df85-f3f8-42e7-a560-96522c9c03b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Collecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2HLPMs23Tuz",
        "outputId": "7c8d656c-8939-4f24-bfcd-caaf8d8b5700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Libclang in /usr/local/lib/python3.10/dist-packages (16.0.6)\n"
          ]
        }
      ],
      "source": [
        "! pip install Libclang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWNTELPY2SPR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import pickle\n",
        "import re\n",
        "import torch\n",
        "import sklearn\n",
        "import os\n",
        "import random\n",
        "import custom\n",
        "import models\n",
        "import clang\n",
        "from clang import *\n",
        "from clang import cindex\n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
        "from transformers import RobertaConfig\n",
        "from transformers import RobertaForMaskedLM, RobertaForSequenceClassification\n",
        "from transformers import RobertaTokenizerFast\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import LineByLineTextDataset\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from custom import CustomDataCollatorForLanguageModeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6rr8OLT2BxJ"
      },
      "source": [
        "## Pre-requisites stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-QBoBH_2BxN",
        "outputId": "204f3b40-fdb8-4283-961a-1072e143ef7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "## Set default device (GPU or CPU)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlWPK-b22BxO"
      },
      "outputs": [],
      "source": [
        "## Deterministic/reproducible flags\n",
        "\n",
        "seedlist = [42, 834, 692, 489, 901, 408, 819, 808, 531, 166]\n",
        "\n",
        "seed = seedlist[0]\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDMga2Su2BxP"
      },
      "outputs": [],
      "source": [
        "## Weights and Biases flags\n",
        "\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "os.environ['WANDB_MODE'] = 'dryrun'\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
        "#os.environ['WANDB_NOTEBOOK_NAME'] = 'Pretrain word-level VulBERTa on Draper'\n",
        "#os.environ['WANDB_NAME'] = 'linux'\n",
        "#os.environ['WANDB_PROJECT'] = 'projectName'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ILQfOoc2BxQ"
      },
      "source": [
        "## Load/initialise custom tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5BF-KXh2BxR"
      },
      "outputs": [],
      "source": [
        "## Tokenizer\n",
        "\n",
        "from tokenizers.pre_tokenizers import PreTokenizer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers import NormalizedString,PreTokenizedString\n",
        "from typing import List\n",
        "\n",
        "class MyTokenizer:\n",
        "\n",
        "    cidx = cindex.Index.create()\n",
        "\n",
        "\n",
        "    def clang_split(self, i: int, normalized_string: NormalizedString) -> List[NormalizedString]:\n",
        "        ## Tokkenize using clang\n",
        "        tok = []\n",
        "        tu = self.cidx.parse('tmp.c',\n",
        "                       args=[''],\n",
        "                       unsaved_files=[('tmp.c', str(normalized_string.original))],\n",
        "                       options=0)\n",
        "        for t in tu.get_tokens(extent=tu.cursor.extent):\n",
        "            spelling = t.spelling.strip()\n",
        "\n",
        "            if spelling == '':\n",
        "                continue\n",
        "\n",
        "            ## Keyword no need\n",
        "\n",
        "            ## Punctuations no need\n",
        "\n",
        "            ## Literal all to BPE\n",
        "\n",
        "            #spelling = spelling.replace(' ', '')\n",
        "            tok.append(NormalizedString(spelling))\n",
        "\n",
        "        return(tok)\n",
        "\n",
        "    def pre_tokenize(self, pretok: PreTokenizedString):\n",
        "        pretok.split(self.clang_split)\n",
        "\n",
        "## Custom tokenizer\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers import normalizers,decoders\n",
        "from tokenizers.normalizers import StripAccents, unicode_normalizer_from_str, Replace\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from tokenizers import processors,pre_tokenizers\n",
        "from tokenizers.models import BPE\n",
        "\n",
        "## Load pre-trained tokenizers\n",
        "vocab, merges = BPE.read_file(vocab=\"./tokenizer/drapgh-vocab.json\", merges=\"./tokenizer/drapgh-merges.txt\")\n",
        "my_tokenizer = Tokenizer(BPE(vocab, merges, unk_token=\"<unk>\"))\n",
        "\n",
        "my_tokenizer.normalizer = normalizers.Sequence([StripAccents(), Replace(\" \", \"Ä\")])\n",
        "my_tokenizer.pre_tokenizer = PreTokenizer.custom(MyTokenizer())\n",
        "my_tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
        "my_tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"<s> $A </s>\",\n",
        "    special_tokens=[\n",
        "    (\"<s>\",0),\n",
        "    (\"<pad>\",1),\n",
        "    (\"</s>\",2),\n",
        "    (\"<unk>\",3),\n",
        "    (\"<mask>\",4)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPN2R6Y_2BxT"
      },
      "source": [
        "### Choose and prepare testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB0yWsBd2BxU"
      },
      "outputs": [],
      "source": [
        "### Choose the dataset ('draper','vuldeepecker','devign','reveal')\n",
        "#mydataset = 'mvd'\n",
        "# added\n",
        "mydataset = \"devign\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4KmjXnR2BxV"
      },
      "outputs": [],
      "source": [
        "my_tokenizer.enable_truncation(max_length=1024)\n",
        "my_tokenizer.enable_padding(direction='right', pad_id=1, pad_type_id=0, pad_token='<pad>', length=None, pad_to_multiple_of=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3GmNM-R2BxW"
      },
      "outputs": [],
      "source": [
        "def process_encodings(encodings):\n",
        "    input_ids=[]\n",
        "    attention_mask=[]\n",
        "    for enc in encodings:\n",
        "        input_ids.append(enc.ids)\n",
        "        attention_mask.append(enc.attention_mask)\n",
        "    return {'input_ids':input_ids, 'attention_mask':attention_mask}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnEtifXn2BxX"
      },
      "outputs": [],
      "source": [
        "def cleaner(code):\n",
        "    ## Remove code comments\n",
        "    pat = re.compile(r'(/\\*([^*]|(\\*+[^*/]))*\\*+/)|(//.*)')\n",
        "    code = re.sub(pat,'',code)\n",
        "    code = re.sub('\\n','',code)\n",
        "    code = re.sub('\\t','',code)\n",
        "    return(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ffult0I2BxY"
      },
      "outputs": [],
      "source": [
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "        assert len(self.encodings['input_ids']) == len(self.encodings['attention_mask']) ==  len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhf-AHXe3vRi",
        "outputId": "ba274b60-92f1-4b59-b963-07325633d072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa/data\n"
          ]
        }
      ],
      "source": [
        "#cd data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiXI2kIT3wus",
        "outputId": "3efcdf91-ae37-47a6-9237-984b9007c07f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-07-28 23:39:44--  https://onedrive.live.com/download?cid=15E206B36A9C8AE7&resid=15E206B36A9C8AE7%21300801&authkey=AMLXq2nFAmlQYAw\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2023-07-28 23:39:45 ERROR 403: Forbidden.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#! wget --no-check-certificate -O data.zip \"https://onedrive.live.com/download?cid=15E206B36A9C8AE7&resid=15E206B36A9C8AE7%21300801&authkey=AMLXq2nFAmlQYAw\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TNdnlwUBEklf",
        "outputId": "048fb87c-ae2d-413e-f50c-dfe671c7bb90"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa/data'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG1ENR0I3_mj",
        "outputId": "6b5aa5e3-eaf0-49e5-a78e-d2b724d0ae44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: tokenizer/\n",
            "  inflating: tokenizer/drapgh.txt    \n",
            "  inflating: __MACOSX/tokenizer/._drapgh.txt  \n",
            "   creating: finetune/\n",
            "   creating: finetune/devign/\n",
            "   creating: finetune/mvd/\n",
            "   creating: finetune/draper/\n",
            "   creating: finetune/reveal/\n",
            "   creating: finetune/vuldeepecker/\n",
            "   creating: finetune/d2a/\n",
            "   creating: finetune/.ipynb_checkpoints/\n",
            "  inflating: finetune/devign/Devign.json  \n",
            "  inflating: __MACOSX/finetune/devign/._Devign.json  \n",
            "  inflating: finetune/devign/train.txt  \n",
            "  inflating: __MACOSX/finetune/devign/._train.txt  \n",
            "  inflating: finetune/devign/valid.txt  \n",
            "  inflating: __MACOSX/finetune/devign/._valid.txt  \n",
            "  inflating: finetune/devign/test.txt  \n",
            "  inflating: __MACOSX/finetune/devign/._test.txt  \n",
            "  inflating: finetune/mvd/mvd_test.pkl  \n",
            "  inflating: __MACOSX/finetune/mvd/._mvd_test.pkl  \n",
            "  inflating: finetune/mvd/mvd_train.pkl  \n",
            "  inflating: __MACOSX/finetune/mvd/._mvd_train.pkl  \n",
            "  inflating: finetune/mvd/mvd_val.pkl  \n",
            "  inflating: __MACOSX/finetune/mvd/._mvd_val.pkl  \n",
            "  inflating: finetune/draper/draper_train.pkl  \n",
            "  inflating: __MACOSX/finetune/draper/._draper_train.pkl  \n",
            "  inflating: finetune/draper/draper_test.pkl  \n",
            "  inflating: __MACOSX/finetune/draper/._draper_test.pkl  \n",
            "  inflating: finetune/draper/draper_val.pkl  \n",
            "  inflating: __MACOSX/finetune/draper/._draper_val.pkl  \n",
            "  inflating: finetune/reveal/reveal_val.pkl  \n",
            "  inflating: __MACOSX/finetune/reveal/._reveal_val.pkl  \n",
            "  inflating: finetune/reveal/reveal_train.pkl  \n",
            "  inflating: __MACOSX/finetune/reveal/._reveal_train.pkl  \n",
            "  inflating: finetune/reveal/reveal_test.pkl  \n",
            "  inflating: __MACOSX/finetune/reveal/._reveal_test.pkl  \n",
            "  inflating: finetune/vuldeepecker/vuldeepecker_test.pkl  \n",
            "  inflating: __MACOSX/finetune/vuldeepecker/._vuldeepecker_test.pkl  \n",
            "  inflating: finetune/vuldeepecker/vuldeepecker_train.pkl  \n",
            "  inflating: __MACOSX/finetune/vuldeepecker/._vuldeepecker_train.pkl  \n",
            "  inflating: finetune/vuldeepecker/vuldeepecker_val.pkl  \n",
            "  inflating: __MACOSX/finetune/vuldeepecker/._vuldeepecker_val.pkl  \n",
            "   creating: finetune/d2a/function/\n",
            "   creating: finetune/d2a/.ipynb_checkpoints/\n",
            "  inflating: finetune/d2a/function/d2a_lbv1_function_test.csv  \n",
            "  inflating: __MACOSX/finetune/d2a/function/._d2a_lbv1_function_test.csv  \n",
            "  inflating: finetune/d2a/function/d2a_lbv1_function_dev.csv  \n",
            "  inflating: __MACOSX/finetune/d2a/function/._d2a_lbv1_function_dev.csv  \n",
            "  inflating: finetune/d2a/function/d2a_lbv1_function_train.csv  \n",
            "  inflating: __MACOSX/finetune/d2a/function/._d2a_lbv1_function_train.csv  \n",
            "   creating: pretrain/\n",
            "  inflating: pretrain/drapgh.pkl     \n",
            "  inflating: __MACOSX/pretrain/._drapgh.pkl  \n"
          ]
        }
      ],
      "source": [
        "#!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nawa8yunGDxO",
        "outputId": "43bf5696-a054-4078-ad94-ab1acc0cc7e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa\n"
          ]
        }
      ],
      "source": [
        "#cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJMMX3A9y_Os"
      },
      "outputs": [],
      "source": [
        "# bigVul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PeyE5erzAdV"
      },
      "outputs": [],
      "source": [
        "f1 = open('data/finetune/devign/test.txt',\"w\")\n",
        "i =0\n",
        "for line in range(0,17662):\n",
        "  f1.write(str(i))\n",
        "  f1.write(\"\\n\")\n",
        "  i += 1\n",
        "f1.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3pXNXJv2BxZ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "if mydataset=='devign':\n",
        "    test_index=set()\n",
        "\n",
        "    with open('data/finetune/devign/test.txt') as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            test_index.add(int(line))\n",
        "    # original test\n",
        "    #mydata = pd.read_json('data/finetune/devign/Devign.json')\n",
        "    # bigVul as test\n",
        "    #mydata = pd.read_json('data/finetune/devign/dfBigVulFinal.jsonl', line = True)\n",
        "    mydata = []\n",
        "    with open('data/finetune/devign/dfBigVulFinal.jsonl', 'r') as f:\n",
        "      for line in f:\n",
        "          mydata.append(json.loads(line))\n",
        "    # added\n",
        "    m3 = pd.DataFrame(mydata)\n",
        "    #m3=mydata.iloc[list(test_index)]\n",
        "    m3=m3.iloc[list(test_index)]\n",
        "    mydata = None\n",
        "    del(mydata)\n",
        "    m3.func = m3.func.apply(cleaner)\n",
        "\n",
        "    test_encodings = my_tokenizer.encode_batch(m3.func)\n",
        "    test_encodings = process_encodings(test_encodings)\n",
        "    test_dataset = MyCustomDataset(test_encodings, m3.target.tolist())\n",
        "else:\n",
        "    m3 = pd.read_pickle('data/finetune/%s/%s_test.pkl'%(mydataset,mydataset))\n",
        "\n",
        "\n",
        "    try:\n",
        "        m3.functionSource = m3.functionSource.apply(cleaner)\n",
        "        test_encodings = my_tokenizer.encode_batch(m3.functionSource)\n",
        "        test_encodings = process_encodings(test_encodings)\n",
        "\n",
        "        if  mydataset =='draper':\n",
        "            test_dataset = MyCustomDataset(test_encodings, (m3['combine']*1).tolist())\n",
        "        else:\n",
        "            test_dataset = MyCustomDataset(test_encodings, m3.label.tolist())\n",
        "    except:\n",
        "        m3.func = m3.func.apply(cleaner)\n",
        "        test_encodings = my_tokenizer.encode_batch(m3.func)\n",
        "        test_encodings = process_encodings(test_encodings)\n",
        "        test_dataset = MyCustomDataset(test_encodings, m3.label.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devign"
      ],
      "metadata": {
        "id": "_k-bwYaj4OKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if mydataset=='devign':\n",
        "    test_index=set()\n",
        "\n",
        "    with open('data/finetune/devign/test.txt') as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            test_index.add(int(line))\n",
        "    mydata = pd.read_json('data/finetune/devign/Devign.json')\n",
        "    m3=mydata.iloc[list(test_index)]\n",
        "\n",
        "    mydata = None\n",
        "    del(mydata)\n",
        "    m3.func = m3.func.apply(cleaner)\n",
        "\n",
        "    test_encodings = my_tokenizer.encode_batch(m3.func)\n",
        "    test_encodings = process_encodings(test_encodings)\n",
        "    test_dataset = MyCustomDataset(test_encodings, m3.target.tolist())\n",
        "else:\n",
        "    m3 = pd.read_pickle('data/finetune/%s/%s_test.pkl'%(mydataset,mydataset))\n",
        "\n",
        "\n",
        "    try:\n",
        "        m3.functionSource = m3.functionSource.apply(cleaner)\n",
        "        test_encodings = my_tokenizer.encode_batch(m3.functionSource)\n",
        "        test_encodings = process_encodings(test_encodings)\n",
        "\n",
        "        if  mydataset =='draper':\n",
        "            test_dataset = MyCustomDataset(test_encodings, (m3['combine']*1).tolist())\n",
        "        else:\n",
        "            test_dataset = MyCustomDataset(test_encodings, m3.label.tolist())\n",
        "    except:\n",
        "        m3.func = m3.func.apply(cleaner)\n",
        "        test_encodings = my_tokenizer.encode_batch(m3.func)\n",
        "        test_encodings = process_encodings(test_encodings)\n",
        "        test_dataset = MyCustomDataset(test_encodings, m3.label.tolist())"
      ],
      "metadata": {
        "id": "DfwzSp0O4PEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_knfi8SuSoyj",
        "outputId": "c61f8033-3c66-4e9b-dedf-0164830cac52"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyHouT1eUT1f",
        "outputId": "d3f65ec1-5d0a-4f27-bed2-de72bb8c1408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xzkNr5WXxSF"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "# Replace 'YOUR_ONEDRIVE_URL' with the actual direct download link\n",
        "file_url = 'https://onedrive.live.com/download?cid=15E206B36A9C8AE7&resid=15E206B36A9C8AE7%21300802&authkey=AFnlaFjZFQCCp5w'\n",
        "\n",
        "# Define the local filename you want to save the file as\n",
        "local_filename = 'models/pretraining_model.zip'  # You can change the name and extension as needed\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(file_url, local_filename, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0graiD-H8AB",
        "outputId": "4628d86b-fdb7-498d-b294-29f7d40fba12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  models/pretraining_model.zip\n",
            "replace VulBERTa/rng_state.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: VulBERTa/rng_state.pth  \n",
            "replace __MACOSX/VulBERTa/._rng_state.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/VulBERTa/._rng_state.pth  \n",
            "replace VulBERTa/optimizer.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: VulBERTa/optimizer.pt   y\n",
            "y\n",
            "y\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBZdLwU2Tka4",
        "outputId": "a623d551-9a8e-46ad-bd46-5e59358e7bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa/models\n"
          ]
        }
      ],
      "source": [
        "cd models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-9h8BKEVmqu",
        "outputId": "c5e4d989-f7c1-4a4c-e836-bcd14c0474b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uyqk-bVV1g7"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "# Replace 'YOUR_ONEDRIVE_URL' with the actual direct download link\n",
        "file_url = 'https://onedrive.live.com/download?cid=15E206B36A9C8AE7&resid=15E206B36A9C8AE7%21300803&authkey=AIj7B7HPzR0lljI'\n",
        "\n",
        "# Define the local filename you want to save the file as\n",
        "local_filename = 'models/finetuning_models.zip'  # You can change the name and extension as needed\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(file_url, local_filename, quiet=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H57SxOq8ZK-O"
      },
      "outputs": [],
      "source": [
        "!unzip models/pretraining_model.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqQ44j_0Zr4g"
      },
      "outputs": [],
      "source": [
        "!unzip models/finetuning_models.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "Qssj4E0E2Bxa",
        "outputId": "63163a37-123f-406c-9239-91e6867abf56"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5ad532bb7344>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## D2A ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'function'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/finetune/%s/%s/d2a_lbv1_%s_val.csv'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/finetune/devign/function/d2a_lbv1_function_val.csv'"
          ]
        }
      ],
      "source": [
        "## D2A ONLY\n",
        "task = 'function'\n",
        "m3 = pd.read_csv('data/finetune/%s/%s/d2a_lbv1_%s_val.csv'%(mydataset,task,task))\n",
        "m3.code = m3.code.apply(cleaner)\n",
        "test_encodings = my_tokenizer.encode_batch(m3.code)\n",
        "test_encodings = process_encodings(test_encodings)\n",
        "test_dataset = MyCustomDataset(test_encodings, m3.label.tolist())\n",
        "#test_dataset = MyCustomDataset(test_encodings, [0]*len(m3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40US6oBq2Bxa"
      },
      "source": [
        "## Load fine-tuned VulBERTa-MLP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ohE0nDK1b_QA",
        "outputId": "5936c2e8-47e5-426a-dc69-b79e89e6e629"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/ReportCC++/vulberta/VulBERTa'"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy2KtF3B2Bxb"
      },
      "outputs": [],
      "source": [
        "mymodel=mydataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSOFG_Mq2Bxb",
        "outputId": "4ea567d6-f2f4-49c2-bed5-7eb9c5f6d9e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124836866\n"
          ]
        }
      ],
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained('./models/VB-MLP_%s' % mymodel)\n",
        "print(model.num_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jWCRhZh2Bxc"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EEyTbxL2Bxc"
      },
      "outputs": [],
      "source": [
        "def softmax_accuracy(probs,all_labels):\n",
        "    def getClass(x):\n",
        "        return(x.index(max(x)))\n",
        "\n",
        "    all_labels = all_labels.tolist()\n",
        "    probs = pd.Series(probs.tolist())\n",
        "    all_predicted = probs.apply(getClass)\n",
        "    all_predicted.reset_index(drop=True, inplace=True)\n",
        "    vc = pd.value_counts(all_predicted == all_labels)\n",
        "    try:\n",
        "        acc = vc[1]/len(all_labels)\n",
        "    except:\n",
        "        if(vc.index[0]==False):\n",
        "            acc = 0\n",
        "        else:\n",
        "            acc = 1\n",
        "    return(acc,all_predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT4wPw-82Bxd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "multigpu=True\n",
        "if multigpu:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgmvoIqV2Bxd"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7-AZ74K2Bxe",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "all_pred=[]\n",
        "all_labels=[]\n",
        "all_probs=[]\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        acc_val,pred = softmax_accuracy(torch.nn.functional.softmax(outputs[1],dim=1),labels)\n",
        "        all_pred += pred.tolist()\n",
        "        all_labels += labels.tolist()\n",
        "        all_probs += outputs[1].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfOk3ePH2Bxe"
      },
      "source": [
        "### Calculate the evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwf_C3yC2Bxf"
      },
      "outputs": [],
      "source": [
        "confusion = sklearn.metrics.confusion_matrix(y_true=all_labels, y_pred=all_pred)\n",
        "print('Confusion matrix: \\n',confusion)\n",
        "\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "print('\\nTP:',tp)\n",
        "print('FP:',fp)\n",
        "print('TN:',tn)\n",
        "print('FN:',fn)\n",
        "\n",
        "probs2=[]\n",
        "for x in all_probs:\n",
        "    probs2.append(x[1])\n",
        "\n",
        "## Performance measure\n",
        "print('\\nAccuracy: '+ str(sklearn.metrics.accuracy_score(y_true=all_labels, y_pred=all_pred)))\n",
        "print('Precision: '+ str(sklearn.metrics.precision_score(y_true=all_labels, y_pred=all_pred)))\n",
        "print('Recall: '+ str(sklearn.metrics.recall_score(y_true=all_labels, y_pred=all_pred)))\n",
        "print('F-measure: '+ str(sklearn.metrics.f1_score(y_true=all_labels, y_pred=all_pred)))\n",
        "print('Precision-Recall AUC: '+ str(sklearn.metrics.average_precision_score(y_true=all_labels, y_score=probs2)))\n",
        "print('AUC: '+ str(sklearn.metrics.roc_auc_score(y_true=all_labels, y_score=probs2)))\n",
        "print('MCC: '+ str(sklearn.metrics.matthews_corrcoef(y_true=all_labels, y_pred=all_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TN = 5579\n",
        "FP = 3343\n",
        "FN = 5536\n",
        "TP = 3204\n",
        "\n",
        "# Precision and Recall for class 0 (negative class)\n",
        "Precision_0 = TN / (TN + FP)\n",
        "Recall_0 = TN / (TN + FN)\n",
        "\n",
        "# Precision and Recall for class 1 (positive class)\n",
        "Precision_1 = TP / (TP + FP)\n",
        "Recall_1 = TP / (TP + FN)\n",
        "\n",
        "print(\"Precision for Class 0 (negative class):\", Precision_0)\n",
        "print(\"Recall for Class 0 (negative class):\", Recall_0)\n",
        "print(\"Precision for Class 1 (positive class):\", Precision_1)\n",
        "print(\"Recall for Class 1 (positive class):\", Recall_1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydMQKWCALtBR",
        "outputId": "ff53153f-5235-4842-8a9d-6b1a4a85112c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Class 0 (negative class): 0.6253082268549652\n",
            "Recall for Class 0 (negative class): 0.5019343229869546\n",
            "Precision for Class 1 (positive class): 0.48938445089353905\n",
            "Recall for Class 1 (positive class): 0.3665903890160183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your confusion matrix values\n",
        "TN = 5579\n",
        "FP = 3343\n",
        "FN = 5536\n",
        "TP = 3204\n",
        "\n",
        "# Calculate the number of instances in each class\n",
        "total_class_0 = TN + FP\n",
        "total_class_1 = FN + TP\n",
        "\n",
        "print(\"Total instances in Class 0:\", total_class_0)\n",
        "print(\"Total instances in Class 1:\", total_class_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOyc-ksKMPwn",
        "outputId": "5b01321f-4c2a-41e9-f252-4790e4f28f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total instances in Class 0: 8922\n",
            "Total instances in Class 1: 8740\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}